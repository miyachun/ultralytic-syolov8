{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6MPjfT5NrKQ"
      },
      "source": [
        "<div align=\"center\">\n",
        "\n",
        "  <a href=\"https://ultralytics.com/yolov8\" target=\"_blank\">\n",
        "    <img width=\"1024\", src=\"https://raw.githubusercontent.com/ultralytics/assets/main/yolov8/banner-yolov8.png\"></a>\n",
        "\n",
        "  [‰∏≠Êñá](https://docs.ultralytics.com/zh/) | [ÌïúÍµ≠Ïñ¥](https://docs.ultralytics.com/ko/) | [Êó•Êú¨Ë™û](https://docs.ultralytics.com/ja/) | [–†—É—Å—Å–∫–∏–π](https://docs.ultralytics.com/ru/) | [Deutsch](https://docs.ultralytics.com/de/) | [Fran√ßais](https://docs.ultralytics.com/fr/) | [Espa√±ol](https://docs.ultralytics.com/es/) | [Portugu√™s](https://docs.ultralytics.com/pt/) | [T√ºrk√ße](https://docs.ultralytics.com/tr/) | [Ti·∫øng Vi·ªát](https://docs.ultralytics.com/vi/) | [‡§π‡§ø‡§®‡•ç‡§¶‡•Ä](https://docs.ultralytics.com/hi/) | [ÿßŸÑÿπÿ±ÿ®Ÿäÿ©](https://docs.ultralytics.com/ar/)\n",
        "\n",
        "  <a href=\"https://github.com/ultralytics/ultralytics/actions/workflows/ci.yaml\"><img src=\"https://github.com/ultralytics/ultralytics/actions/workflows/ci.yaml/badge.svg\" alt=\"Ultralytics CI\"></a>\n",
        "  <a href=\"https://console.paperspace.com/github/ultralytics/ultralytics\"><img src=\"https://assets.paperspace.io/img/gradient-badge.svg\" alt=\"Run on Gradient\"/></a>\n",
        "  <a href=\"https://colab.research.google.com/github/ultralytics/ultralytics/blob/main/examples/tutorial.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a>\n",
        "  <a href=\"https://www.kaggle.com/ultralytics/yolov8\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" alt=\"Open In Kaggle\"></a>\n",
        "  <a href=\"https://ultralytics.com/discord\"><img alt=\"Discord\" src=\"https://img.shields.io/discord/1089800235347353640?logo=discord&logoColor=white&label=Discord&color=blue\"></a>\n",
        "\n",
        "Welcome to the Ultralytics YOLOv8 üöÄ notebook! <a href=\"https://github.com/ultralytics/ultralytics\">YOLOv8</a> is the latest version of the YOLO (You Only Look Once) AI models developed by <a href=\"https://ultralytics.com\">Ultralytics</a>. This notebook serves as the starting point for exploring the various resources available to help you get started with YOLOv8 and understand its features and capabilities.\n",
        "\n",
        "YOLOv8 models are fast, accurate, and easy to use, making them ideal for various object detection and image segmentation tasks. They can be trained on large datasets and run on diverse hardware platforms, from CPUs to GPUs.\n",
        "\n",
        "We hope that the resources in this notebook will help you get the most out of YOLOv8. Please browse the YOLOv8 <a href=\"https://docs.ultralytics.com/\">Docs</a> for details, raise an issue on <a href=\"https://github.com/ultralytics/ultralytics\">GitHub</a> for support, and join our <a href=\"https://ultralytics.com/discord\">Discord</a> community for questions and discussions!\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mGmQbAO5pQb"
      },
      "source": [
        "# Setup\n",
        "\n",
        "Pip install `ultralytics` and [dependencies](https://github.com/ultralytics/ultralytics/blob/main/pyproject.toml) and check software and hardware.\n",
        "\n",
        "[![PyPI - Version](https://img.shields.io/pypi/v/ultralytics?logo=pypi&logoColor=white)](https://pypi.org/project/ultralytics/) [![Downloads](https://static.pepy.tech/badge/ultralytics)](https://pepy.tech/project/ultralytics) [![PyPI - Python Version](https://img.shields.io/pypi/pyversions/ultralytics?logo=python&logoColor=gold)](https://pypi.org/project/ultralytics/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbvMlHd_QwMG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a6d1911-a6d5-409b-fded-1965882e3b4d"
      },
      "source": [
        "%pip install ultralytics\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.2.66 üöÄ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Setup complete ‚úÖ (2 CPUs, 12.7 GB RAM, 29.7/78.2 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JnkELT0cIJg"
      },
      "source": [
        "# 1. Predict\n",
        "\n",
        "YOLOv8 may be used directly in the Command Line Interface (CLI) with a `yolo` command for a variety of tasks and modes and accepts additional arguments, i.e. `imgsz=640`. See a full list of available `yolo` [arguments](https://docs.ultralytics.com/usage/cfg/) and other details in the [YOLOv8 Predict Docs](https://docs.ultralytics.com/modes/train/).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zR9ZbuQCH7FX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d704a73f-d9dc-4603-ae11-34d6c84781f0"
      },
      "source": [
        "# Run inference on an image with YOLOv8n\n",
        "!yolo predict model=yolov8n.pt source='https://ultralytics.com/images/zidane.jpg'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt to 'yolov8n.pt'...\n",
            "100% 6.25M/6.25M [00:00<00:00, 89.7MB/s]\n",
            "Ultralytics YOLOv8.2.66 üöÄ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLOv8n summary (fused): 168 layers, 3,151,904 parameters, 0 gradients, 8.7 GFLOPs\n",
            "\n",
            "Downloading https://ultralytics.com/images/zidane.jpg to 'zidane.jpg'...\n",
            "100% 49.2k/49.2k [00:00<00:00, 6.45MB/s]\n",
            "image 1/1 /content/zidane.jpg: 384x640 2 persons, 1 tie, 167.8ms\n",
            "Speed: 11.3ms preprocess, 167.8ms inference, 1059.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
            "üí° Learn more at https://docs.ultralytics.com/modes/predict\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkAzDWJ7cWTr"
      },
      "source": [
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
        "<img align=\"left\" src=\"https://user-images.githubusercontent.com/26833433/212889447-69e5bdf1-5800-4e29-835e-2ed2336dede2.jpg\" width=\"600\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eq1SMWl6Sfn"
      },
      "source": [
        "# 2. Val\n",
        "Validate a model's accuracy on the [COCO](https://docs.ultralytics.com/datasets/detect/coco/) dataset's `val` or `test` splits. The latest YOLOv8 [models](https://github.com/ultralytics/ultralytics#models) are downloaded automatically the first time they are used. See [YOLOv8 Val Docs](https://docs.ultralytics.com/modes/val/) for more information."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQPtK1QYVaD_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60de1dd9-1581-474e-a842-7d6bc37d24b8"
      },
      "source": [
        "# Download COCO val\n",
        "import torch\n",
        "torch.hub.download_url_to_file('https://ultralytics.com/assets/coco2017val.zip', 'tmp.zip')  # download (780M - 5000 images)\n",
        "!unzip -q tmp.zip -d datasets && rm tmp.zip  # unzip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 780M/780M [00:03<00:00, 208MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X58w8JLpMnjH",
        "outputId": "08890bc1-6d09-4924-ca69-4eaf42a57f84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Validate YOLOv8n on COCO8 val\n",
        "!yolo val model=yolov8n.pt data=coco8.yaml"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.2.66 üöÄ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLOv8n summary (fused): 168 layers, 3,151,904 parameters, 0 gradients, 8.7 GFLOPs\n",
            "\n",
            "Dataset 'coco8.yaml' images not found ‚ö†Ô∏è, missing path '/content/datasets/coco8/images/val'\n",
            "Downloading https://ultralytics.com/assets/coco8.zip to '/content/datasets/coco8.zip'...\n",
            "100% 433k/433k [00:00<00:00, 14.1MB/s]\n",
            "Unzipping /content/datasets/coco8.zip to /content/datasets/coco8...: 100% 25/25 [00:00<00:00, 4839.28file/s]\n",
            "Dataset download success ‚úÖ (0.6s), saved to \u001b[1m/content/datasets\u001b[0m\n",
            "\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n",
            "100% 755k/755k [00:00<00:00, 22.8MB/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/coco8/labels/val... 4 images, 0 backgrounds, 0 corrupt: 100% 4/4 [00:00<00:00, 179.33it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/coco8/labels/val.cache\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:02<00:00,  2.45s/it]\n",
            "                   all          4         17      0.621      0.833      0.888       0.63\n",
            "                person          3         10      0.721        0.5      0.519      0.269\n",
            "                   dog          1          1       0.37          1      0.995      0.597\n",
            "                 horse          1          2      0.751          1      0.995      0.631\n",
            "              elephant          1          2      0.505        0.5      0.828      0.394\n",
            "              umbrella          1          1      0.564          1      0.995      0.995\n",
            "          potted plant          1          1      0.814          1      0.995      0.895\n",
            "Speed: 0.3ms preprocess, 66.3ms inference, 0.0ms loss, 188.1ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val\u001b[0m\n",
            "üí° Learn more at https://docs.ultralytics.com/modes/val\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY2VXXXu74w5"
      },
      "source": [
        "# 3. Train\n",
        "\n",
        "<p align=\"\"><a href=\"https://ultralytics.com/hub\"><img width=\"1000\" src=\"https://github.com/ultralytics/assets/raw/main/yolov8/banner-integrations.png\"/></a></p>\n",
        "\n",
        "Train YOLOv8 on [Detect](https://docs.ultralytics.com/tasks/detect/), [Segment](https://docs.ultralytics.com/tasks/segment/), [Classify](https://docs.ultralytics.com/tasks/classify/) and [Pose](https://docs.ultralytics.com/tasks/pose/) datasets. See [YOLOv8 Train Docs](https://docs.ultralytics.com/modes/train/) for more information."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Select YOLOv8 üöÄ logger {run: 'auto'}\n",
        "logger = 'Comet' #@param ['Comet', 'TensorBoard']\n",
        "\n",
        "if logger == 'Comet':\n",
        "  %pip install -q comet_ml\n",
        "  import comet_ml; comet_ml.init()\n",
        "elif logger == 'TensorBoard':\n",
        "  %load_ext tensorboard\n",
        "  %tensorboard --logdir ."
      ],
      "metadata": {
        "id": "ktegpM42AooT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b935760c-f0ff-4727-89fd-e1beb895ff2e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/682.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m \u001b[32m675.8/682.3 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m682.3/682.3 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/979.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m979.1/979.1 kB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/3.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m136.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m68.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m303.6/303.6 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m137.9/137.9 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m comet_ml.init() is deprecated and will be removed soon. Please use comet_ml.login()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please paste your Comet API key from https://www.comet.com/api/my/settings/\n",
            "(api key may not show as you type)\n",
            "Comet API key: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Valid Comet API Key saved in /root/.comet.config (set COMET_CONFIG to change where it is saved).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NcFxRcFdJ_O",
        "outputId": "afcdc4a5-4064-44cb-ad70-3f3007fe7e07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Train YOLOv8n on COCO8 for 3 epochs\n",
        "!yolo train model=yolov8n.pt data=coco8.yaml epochs=3 imgsz=640"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.2.66 üöÄ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=coco8.yaml, epochs=3, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n",
            "Model summary: 225 layers, 3,157,200 parameters, 3,157,184 gradients, 8.9 GFLOPs\n",
            "\n",
            "Transferred 355/355 items from pretrained weights\n",
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com \u001b[38;5;39mhttps://www.comet.com/miyachun/general/f57b1928764b4e62b9dd30675a8e5361\u001b[0m\n",
            "\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Couldn't find a Git repository in '/content' nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/coco8/labels/train... 4 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 561.88it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/datasets/coco8/labels/train.cache\n",
            "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.12 (you have 1.4.11). Upgrade using: pip install --upgrade albumentations\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/coco8/labels/val.cache... 4 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<?, ?it/s]\n",
            "Plotting labels to runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ‚úÖ\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
            "Starting training for 3 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "        1/3     0.772G      1.039      3.146      1.498         25        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:02<00:00,  2.63s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.37it/s]\n",
            "                   all          4         17       0.62      0.885      0.888      0.621\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "        2/3     0.734G      1.169      2.778      1.442         36        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  8.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 11.58it/s]\n",
            "                   all          4         17      0.595      0.903      0.888      0.616\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "        3/3     0.734G     0.6701      3.696      1.096         17        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  7.34it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  5.67it/s]\n",
            "                   all          4         17      0.577      0.833      0.874      0.614\n",
            "\n",
            "3 epochs completed in 0.003 hours.\n",
            "Optimizer stripped from runs/detect/train/weights/last.pt, 6.5MB\n",
            "Optimizer stripped from runs/detect/train/weights/best.pt, 6.5MB\n",
            "\n",
            "Validating runs/detect/train/weights/best.pt...\n",
            "Ultralytics YOLOv8.2.66 üöÄ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3,151,904 parameters, 0 gradients, 8.7 GFLOPs\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 21.20it/s]\n",
            "                   all          4         17      0.617      0.884      0.888      0.622\n",
            "                person          3         10       0.67        0.5       0.52      0.278\n",
            "                   dog          1          1      0.361          1      0.995      0.597\n",
            "                 horse          1          2      0.728          1      0.995      0.631\n",
            "              elephant          1          2      0.602      0.805      0.828      0.332\n",
            "              umbrella          1          1      0.553          1      0.995      0.995\n",
            "          potted plant          1          1      0.789          1      0.995      0.895\n",
            "Speed: 0.3ms preprocess, 4.0ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train\u001b[0m\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : resident_bilberry_7585\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : \u001b[38;5;39mhttps://www.comet.com/miyachun/general/f57b1928764b4e62b9dd30675a8e5361\u001b[0m\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg0 [7]               : (0.0, 8.092e-07)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg1 [7]               : (0.0, 8.092e-07)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg2 [7]               : (0.0, 8.092e-07)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/mAP50(B) [8]     : (0.87413, 0.8881272943678012)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/mAP50-95(B) [8]  : (0.61421, 0.6215143129723901)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/precision(B) [8] : (0.57709, 0.6198)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/recall(B) [8]    : (0.83333, 0.9032)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/GFLOPs             : 8.858\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/parameters         : 3157200\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/speed_PyTorch(ms)  : 169.635\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/box_loss [6]       : (0.67005, 1.16936)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/cls_loss [6]       : (2.77838, 3.69585)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/dfl_loss [6]       : (1.09625, 1.49841)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/box_loss [6]         : (1.40327, 1.41065)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/cls_loss [6]         : (1.27502, 1.32999)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/dfl_loss [6]         : (1.25176, 1.25417)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_batch_logging_interval  : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     log_confusion_matrix_on_eval : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     log_image_predictions        : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_image_predictions        : 100\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     agnostic_nms    : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     amp             : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     augment         : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     auto_augment    : randaugment\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     batch           : 16\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     bgr             : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     box             : 7.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cache           : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cfg             : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     classes         : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     close_mosaic    : 10\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cls             : 0.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conf            : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     copy_paste      : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cos_lr          : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     crop_fraction   : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     data            : /usr/local/lib/python3.10/dist-packages/ultralytics/cfg/datasets/coco8.yaml\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     degrees         : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     deterministic   : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     device          : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dfl             : 1.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dnn             : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dropout         : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dynamic         : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     embed           : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     epochs          : 3\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     erasing         : 0.4\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     exist_ok        : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fliplr          : 0.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     flipud          : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     format          : torchscript\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fraction        : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     freeze          : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     half            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_h           : 0.015\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_s           : 0.7\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_v           : 0.4\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     imgsz           : 640\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     int8            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     iou             : 0.7\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     keras           : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     kobj            : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     label_smoothing : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     line_width      : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr0             : 0.01\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lrf             : 0.01\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mask_ratio      : 4\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_det         : 300\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mixup           : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mode            : train\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model           : yolov8n.pt\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     momentum        : 0.937\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mosaic          : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     multi_scale     : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name            : train\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     nbs             : 64\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     nms             : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     opset           : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimize        : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimizer       : auto\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     overlap_mask    : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     patience        : 100\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     perspective     : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     plots           : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pose            : 12.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pretrained      : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     profile         : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     project         : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     rect            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     resume          : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     retina_masks    : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save            : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_conf       : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_crop       : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_dir        : runs/detect/train\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_frames     : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_hybrid     : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_json       : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_period     : -1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_txt        : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     scale           : 0.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     seed            : 0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     shear           : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_boxes      : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_conf       : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_labels     : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     simplify        : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     single_cls      : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source          : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     split           : val\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     stream_buffer   : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     task            : detect\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     time            : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tracker         : botsort.yaml\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     translate       : 0.1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val             : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     verbose         : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     vid_stride      : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     visualize       : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_bias_lr  : 0.1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_epochs   : 3.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_momentum : 0.8\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     weight_decay    : 0.0005\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     workers         : 8\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     workspace       : 4\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     confusion-matrix    : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename            : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     images              : 7\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages  : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model-element       : 1 (6.24 MB)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages         : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code         : 2 (13.64 KB)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n",
            "üí° Learn more at https://docs.ultralytics.com/modes/train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Export\n",
        "\n",
        "Export a YOLOv8 model to any supported format below with the `format` argument, i.e. `format=onnx`. See [YOLOv8 Export Docs](https://docs.ultralytics.com/modes/export/) for more information.\n",
        "\n",
        "- üí° ProTip: Export to [ONNX](https://docs.ultralytics.com/integrations/onnx/) or [OpenVINO](https://docs.ultralytics.com/integrations/openvino/) for up to 3x CPU speedup.  \n",
        "- üí° ProTip: Export to [TensorRT](https://docs.ultralytics.com/integrations/tensorrt/) for up to 5x GPU speedup.\n",
        "\n",
        "| Format                                                                   | `format` Argument | Model                     | Metadata | Arguments                                                            |\n",
        "|--------------------------------------------------------------------------|-------------------|---------------------------|----------|----------------------------------------------------------------------|\n",
        "| [PyTorch](https://pytorch.org/)                                          | -                 | `yolov8n.pt`              | ‚úÖ        | -                                                                    |\n",
        "| [TorchScript](https://docs.ultralytics.com/integrations/torchscript)     | `torchscript`     | `yolov8n.torchscript`     | ‚úÖ        | `imgsz`, `optimize`, `batch`                                         |\n",
        "| [ONNX](https://docs.ultralytics.com/integrations/onnx)                   | `onnx`            | `yolov8n.onnx`            | ‚úÖ        | `imgsz`, `half`, `dynamic`, `simplify`, `opset`, `batch`             |\n",
        "| [OpenVINO](https://docs.ultralytics.com/integrations/openvino)           | `openvino`        | `yolov8n_openvino_model/` | ‚úÖ        | `imgsz`, `half`, `int8`, `batch`                                     |\n",
        "| [TensorRT](https://docs.ultralytics.com/integrations/tensorrt)           | `engine`          | `yolov8n.engine`          | ‚úÖ        | `imgsz`, `half`, `dynamic`, `simplify`, `workspace`, `int8`, `batch` |\n",
        "| [CoreML](https://docs.ultralytics.com/integrations/coreml)               | `coreml`          | `yolov8n.mlpackage`       | ‚úÖ        | `imgsz`, `half`, `int8`, `nms`, `batch`                              |\n",
        "| [TF SavedModel](https://docs.ultralytics.com/integrations/tf-savedmodel) | `saved_model`     | `yolov8n_saved_model/`    | ‚úÖ        | `imgsz`, `keras`, `int8`, `batch`                                    |\n",
        "| [TF GraphDef](https://docs.ultralytics.com/integrations/tf-graphdef)     | `pb`              | `yolov8n.pb`              | ‚ùå        | `imgsz`, `batch`                                                     |\n",
        "| [TF Lite](https://docs.ultralytics.com/integrations/tflite)              | `tflite`          | `yolov8n.tflite`          | ‚úÖ        | `imgsz`, `half`, `int8`, `batch`                                     |\n",
        "| [TF Edge TPU](https://docs.ultralytics.com/integrations/edge-tpu)        | `edgetpu`         | `yolov8n_edgetpu.tflite`  | ‚úÖ        | `imgsz`, `batch`                                                     |\n",
        "| [TF.js](https://docs.ultralytics.com/integrations/tfjs)                  | `tfjs`            | `yolov8n_web_model/`      | ‚úÖ        | `imgsz`, `half`, `int8`, `batch`                                     |\n",
        "| [PaddlePaddle](https://docs.ultralytics.com/integrations/paddlepaddle)   | `paddle`          | `yolov8n_paddle_model/`   | ‚úÖ        | `imgsz`, `batch`                                                     |\n",
        "| [NCNN](https://docs.ultralytics.com/integrations/ncnn)                   | `ncnn`            | `yolov8n_ncnn_model/`     | ‚úÖ        | `imgsz`, `half`, `batch`                                             |"
      ],
      "metadata": {
        "id": "nPZZeNrLCQG6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo export model=yolov8n.pt format=torchscript"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYIjW4igCjqD",
        "outputId": "e4668a9c-2fb9-4afe-ba07-7e06c02da6c4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.2.66 üöÄ Python-3.10.12 torch-2.3.1+cu121 CPU (Intel Xeon 2.20GHz)\n",
            "YOLOv8n summary (fused): 168 layers, 3,151,904 parameters, 0 gradients, 8.7 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'yolov8n.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (6.2 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mTorchScript:\u001b[0m starting export with torch 2.3.1+cu121...\n",
            "\u001b[34m\u001b[1mTorchScript:\u001b[0m export success ‚úÖ 3.0s, saved as 'yolov8n.torchscript' (12.4 MB)\n",
            "\n",
            "Export complete (7.9s)\n",
            "Results saved to \u001b[1m/content\u001b[0m\n",
            "Predict:         yolo predict task=detect model=yolov8n.torchscript imgsz=640  \n",
            "Validate:        yolo val task=detect model=yolov8n.torchscript imgsz=640 data=coco.yaml  \n",
            "Visualize:       https://netron.app\n",
            "üí° Learn more at https://docs.ultralytics.com/modes/export\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Python Usage\n",
        "\n",
        "YOLOv8 was reimagined using Python-first principles for the most seamless Python YOLO experience yet. YOLOv8 models can be loaded from a trained checkpoint or created from scratch. Then methods are used to train, val, predict, and export the model. See detailed Python usage examples in the [YOLOv8 Python Docs](https://docs.ultralytics.com/usage/python/)."
      ],
      "metadata": {
        "id": "kUMOQ0OeDBJG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a model\n",
        "model = YOLO('yolov8n.yaml')  # build a new model from scratch\n",
        "model = YOLO('yolov8n.pt')  # load a pretrained model (recommended for training)\n",
        "\n",
        "# Use the model\n",
        "results = model.train(data='coco8.yaml', epochs=3)  # train the model\n",
        "results = model.val()  # evaluate model performance on the validation set\n",
        "results = model('https://ultralytics.com/images/bus.jpg')  # predict on an image\n",
        "results = model.export(format='onnx')  # export the model to ONNX format"
      ],
      "metadata": {
        "id": "bpF9-vS_DAaf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64248583-6eb6-4dfd-d8a6-96565411bfdc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.2.66 üöÄ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=coco8.yaml, epochs=3, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train2\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n",
            "Model summary: 225 layers, 3,157,200 parameters, 3,157,184 gradients, 8.9 GFLOPs\n",
            "\n",
            "Transferred 355/355 items from pretrained weights\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n",
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/miyachun/general/e54d1a310ede4f6386d2a4369362d3df\n",
            "\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Couldn't find a Git repository in '/content' nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train2', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/coco8/labels/train.cache... 4 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/coco8/labels/val.cache... 4 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/detect/train2/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ‚úÖ\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train2\u001b[0m\n",
            "Starting training for 3 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        1/3     0.772G      1.039      3.146      1.498         25        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.04s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          4         17       0.62      0.885      0.888      0.621\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        2/3     0.734G      1.169      2.778      1.442         36        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  5.30it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  6.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          4         17      0.595      0.903      0.888      0.616\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        3/3     0.734G     0.6701      3.696      1.096         17        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  5.09it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  6.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          4         17      0.577      0.833      0.874      0.614\n",
            "\n",
            "3 epochs completed in 0.002 hours.\n",
            "Optimizer stripped from runs/detect/train2/weights/last.pt, 6.5MB\n",
            "Optimizer stripped from runs/detect/train2/weights/best.pt, 6.5MB\n",
            "\n",
            "Validating runs/detect/train2/weights/best.pt...\n",
            "Ultralytics YOLOv8.2.66 üöÄ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3,151,904 parameters, 0 gradients, 8.7 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  9.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          4         17      0.617      0.884      0.888      0.622\n",
            "                person          3         10       0.67        0.5       0.52      0.278\n",
            "                   dog          1          1      0.361          1      0.995      0.597\n",
            "                 horse          1          2      0.728          1      0.995      0.631\n",
            "              elephant          1          2      0.602      0.805      0.828      0.332\n",
            "              umbrella          1          1      0.553          1      0.995      0.995\n",
            "          potted plant          1          1      0.789          1      0.995      0.895\n",
            "Speed: 0.3ms preprocess, 9.3ms inference, 0.0ms loss, 3.9ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train2\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : artificial_wok_140\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/miyachun/general/e54d1a310ede4f6386d2a4369362d3df\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg0 [7]               : (0.0, 8.092e-07)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg1 [7]               : (0.0, 8.092e-07)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg2 [7]               : (0.0, 8.092e-07)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/mAP50(B) [8]     : (0.87413, 0.8881272943678012)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/mAP50-95(B) [8]  : (0.61421, 0.6215143129723901)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/precision(B) [8] : (0.57709, 0.6198)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/recall(B) [8]    : (0.83333, 0.9032)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/GFLOPs             : 8.858\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/parameters         : 3157200\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/speed_PyTorch(ms)  : 127.84\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/box_loss [6]       : (0.67005, 1.16936)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/cls_loss [6]       : (2.77838, 3.69585)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/dfl_loss [6]       : (1.09625, 1.49841)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/box_loss [6]         : (1.40327, 1.41065)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/cls_loss [6]         : (1.27502, 1.32999)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/dfl_loss [6]         : (1.25176, 1.25417)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_batch_logging_interval  : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     log_confusion_matrix_on_eval : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     log_image_predictions        : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_image_predictions        : 100\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     agnostic_nms    : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     amp             : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     augment         : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     auto_augment    : randaugment\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     batch           : 16\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     bgr             : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     box             : 7.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cache           : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cfg             : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     classes         : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     close_mosaic    : 10\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cls             : 0.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conf            : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     copy_paste      : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cos_lr          : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     crop_fraction   : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     data            : /usr/local/lib/python3.10/dist-packages/ultralytics/cfg/datasets/coco8.yaml\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     degrees         : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     deterministic   : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     device          : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dfl             : 1.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dnn             : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dropout         : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dynamic         : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     embed           : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     epochs          : 3\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     erasing         : 0.4\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     exist_ok        : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fliplr          : 0.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     flipud          : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     format          : torchscript\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fraction        : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     freeze          : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     half            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_h           : 0.015\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_s           : 0.7\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_v           : 0.4\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     imgsz           : 640\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     int8            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     iou             : 0.7\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     keras           : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     kobj            : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     label_smoothing : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     line_width      : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr0             : 0.01\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lrf             : 0.01\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mask_ratio      : 4\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_det         : 300\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mixup           : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mode            : train\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model           : yolov8n.pt\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     momentum        : 0.937\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mosaic          : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     multi_scale     : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name            : train2\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     nbs             : 64\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     nms             : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     opset           : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimize        : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimizer       : auto\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     overlap_mask    : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     patience        : 100\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     perspective     : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     plots           : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pose            : 12.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pretrained      : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     profile         : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     project         : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     rect            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     resume          : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     retina_masks    : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save            : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_conf       : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_crop       : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_dir        : runs/detect/train2\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_frames     : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_hybrid     : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_json       : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_period     : -1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_txt        : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     scale           : 0.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     seed            : 0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     shear           : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_boxes      : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_conf       : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_labels     : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     simplify        : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     single_cls      : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source          : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     split           : val\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     stream_buffer   : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     task            : detect\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     time            : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tracker         : botsort.yaml\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     translate       : 0.1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val             : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     verbose         : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     vid_stride      : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     visualize       : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_bias_lr  : 0.1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_epochs   : 3.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_momentum : 0.8\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     weight_decay    : 0.0005\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     workers         : 8\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     workspace       : 4\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     confusion-matrix    : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename            : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     images              : 7\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages  : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model-element       : 1 (6.24 MB)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook            : 2\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages         : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code         : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Please wait for metadata to finish uploading (timeout is 3600 seconds)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Uploading 150 metrics, params and output messages\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.2.66 üöÄ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3,151,904 parameters, 0 gradients, 8.7 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/coco8/labels/val.cache... 4 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<?, ?it/s]\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  5.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          4         17       0.62      0.886      0.888      0.621\n",
            "                person          3         10      0.673        0.5      0.519      0.278\n",
            "                   dog          1          1      0.364          1      0.995      0.597\n",
            "                 horse          1          2      0.732          1      0.995      0.631\n",
            "              elephant          1          2      0.605      0.814      0.828      0.332\n",
            "              umbrella          1          1      0.554          1      0.995      0.995\n",
            "          potted plant          1          1      0.793          1      0.995      0.895\n",
            "Speed: 1.2ms preprocess, 35.2ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train22\u001b[0m\n",
            "\n",
            "Downloading https://ultralytics.com/images/bus.jpg to 'bus.jpg'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 134k/134k [00:00<00:00, 7.60MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image 1/1 /content/bus.jpg: 640x480 4 persons, 1 bus, 1 stop sign, 25.4ms\n",
            "Speed: 6.2ms preprocess, 25.4ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 480)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.2.66 üöÄ Python-3.10.12 torch-2.3.1+cu121 CPU (Intel Xeon 2.20GHz)\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'runs/detect/train2/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (6.2 MB)\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['onnx>=1.12.0'] not found, attempting AutoUpdate...\n",
            "Collecting onnx>=1.12.0\n",
            "  Downloading onnx-1.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from onnx>=1.12.0) (1.25.2)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx>=1.12.0) (3.20.3)\n",
            "Downloading onnx-1.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n",
            "   ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 15.9/15.9 MB 183.6 MB/s eta 0:00:00\n",
            "Installing collected packages: onnx\n",
            "Successfully installed onnx-1.16.1\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ‚úÖ 5.5s, installed 1 package: ['onnx>=1.12.0']\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m ‚ö†Ô∏è \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.16.1 opset 17...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success ‚úÖ 6.4s, saved as 'runs/detect/train2/weights/best.onnx' (12.2 MB)\n",
            "\n",
            "Export complete (8.5s)\n",
            "Results saved to \u001b[1m/content/runs/detect/train2/weights\u001b[0m\n",
            "Predict:         yolo predict task=detect model=runs/detect/train2/weights/best.onnx imgsz=640  \n",
            "Validate:        yolo val task=detect model=runs/detect/train2/weights/best.onnx imgsz=640 data=/usr/local/lib/python3.10/dist-packages/ultralytics/cfg/datasets/coco8.yaml  \n",
            "Visualize:       https://netron.app\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Tasks\n",
        "\n",
        "YOLOv8 can train, val, predict and export models for the most common tasks in vision AI: [Detect](https://docs.ultralytics.com/tasks/detect/), [Segment](https://docs.ultralytics.com/tasks/segment/), [Classify](https://docs.ultralytics.com/tasks/classify/) and [Pose](https://docs.ultralytics.com/tasks/pose/). See [YOLOv8 Tasks Docs](https://docs.ultralytics.com/tasks/) for more information.\n",
        "\n",
        "<br><img width=\"1024\" src=\"https://raw.githubusercontent.com/ultralytics/assets/main/im/banner-tasks.png\">\n"
      ],
      "metadata": {
        "id": "Phm9ccmOKye5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Detection\n",
        "\n",
        "YOLOv8 _detection_ models have no suffix and are the default YOLOv8 models, i.e. `yolov8n.pt` and are pretrained on COCO. See [Detection Docs](https://docs.ultralytics.com/tasks/detect/) for full details.\n"
      ],
      "metadata": {
        "id": "yq26lwpYK1lq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load YOLOv8n, train it on COCO128 for 3 epochs and predict an image with it\n",
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO('yolov8n.pt')  # load a pretrained YOLOv8n detection model\n",
        "model.train(data='coco8.yaml', epochs=3)  # train the model\n",
        "model('https://ultralytics.com/images/bus.jpg')  # predict on an image"
      ],
      "metadata": {
        "id": "8Go5qqS9LbC5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79271b97-6a7e-4d86-a952-98a51911038d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.2.66 üöÄ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=coco8.yaml, epochs=3, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train3, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train3\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n",
            "Model summary: 225 layers, 3,157,200 parameters, 3,157,184 gradients, 8.9 GFLOPs\n",
            "\n",
            "Transferred 355/355 items from pretrained weights\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n",
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/miyachun/general/86ed5127407240b7a57f517cc5bf1eec\n",
            "\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Couldn't find a Git repository in '/content' nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train3', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/coco8/labels/train.cache... 4 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/coco8/labels/val.cache... 4 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/detect/train3/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ‚úÖ\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train3\u001b[0m\n",
            "Starting training for 3 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        1/3     0.789G      1.039      3.146      1.498         25        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  6.50it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          4         17       0.62      0.885      0.888      0.621\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        2/3     0.755G      1.169      2.778      1.442         36        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  7.36it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          4         17      0.595      0.903      0.888      0.616\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        3/3     0.726G     0.6701      3.696      1.096         17        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  5.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          4         17      0.577      0.833      0.874      0.614\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "3 epochs completed in 0.010 hours.\n",
            "Optimizer stripped from runs/detect/train3/weights/last.pt, 6.5MB\n",
            "Optimizer stripped from runs/detect/train3/weights/best.pt, 6.5MB\n",
            "\n",
            "Validating runs/detect/train3/weights/best.pt...\n",
            "Ultralytics YOLOv8.2.66 üöÄ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3,151,904 parameters, 0 gradients, 8.7 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 21.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          4         17      0.617      0.884      0.888      0.622\n",
            "                person          3         10       0.67        0.5       0.52      0.278\n",
            "                   dog          1          1      0.361          1      0.995      0.597\n",
            "                 horse          1          2      0.728          1      0.995      0.631\n",
            "              elephant          1          2      0.602      0.805      0.828      0.332\n",
            "              umbrella          1          1      0.553          1      0.995      0.995\n",
            "          potted plant          1          1      0.789          1      0.995      0.895\n",
            "Speed: 0.3ms preprocess, 4.2ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train3\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : defensive_bobcat_4647\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/miyachun/general/86ed5127407240b7a57f517cc5bf1eec\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg0 [7]               : (0.0, 8.092e-07)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg1 [7]               : (0.0, 8.092e-07)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg2 [7]               : (0.0, 8.092e-07)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/mAP50(B) [8]     : (0.87413, 0.8881272943678012)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/mAP50-95(B) [8]  : (0.61421, 0.6215143129723901)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/precision(B) [8] : (0.57709, 0.6198)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/recall(B) [8]    : (0.83333, 0.9032)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/GFLOPs             : 8.858\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/parameters         : 3157200\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/speed_PyTorch(ms)  : 22.458\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/box_loss [6]       : (0.67005, 1.16936)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/cls_loss [6]       : (2.77838, 3.69585)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/dfl_loss [6]       : (1.09625, 1.49841)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/box_loss [6]         : (1.40327, 1.41065)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/cls_loss [6]         : (1.27502, 1.32999)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/dfl_loss [6]         : (1.25176, 1.25417)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_batch_logging_interval  : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     log_confusion_matrix_on_eval : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     log_image_predictions        : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_image_predictions        : 100\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     agnostic_nms    : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     amp             : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     augment         : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     auto_augment    : randaugment\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     batch           : 16\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     bgr             : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     box             : 7.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cache           : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cfg             : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     classes         : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     close_mosaic    : 10\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cls             : 0.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conf            : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     copy_paste      : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cos_lr          : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     crop_fraction   : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     data            : /usr/local/lib/python3.10/dist-packages/ultralytics/cfg/datasets/coco8.yaml\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     degrees         : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     deterministic   : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     device          : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dfl             : 1.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dnn             : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dropout         : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dynamic         : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     embed           : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     epochs          : 3\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     erasing         : 0.4\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     exist_ok        : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fliplr          : 0.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     flipud          : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     format          : torchscript\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fraction        : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     freeze          : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     half            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_h           : 0.015\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_s           : 0.7\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_v           : 0.4\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     imgsz           : 640\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     int8            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     iou             : 0.7\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     keras           : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     kobj            : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     label_smoothing : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     line_width      : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr0             : 0.01\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lrf             : 0.01\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mask_ratio      : 4\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_det         : 300\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mixup           : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mode            : train\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model           : yolov8n.pt\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     momentum        : 0.937\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mosaic          : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     multi_scale     : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name            : train3\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     nbs             : 64\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     nms             : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     opset           : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimize        : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimizer       : auto\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     overlap_mask    : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     patience        : 100\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     perspective     : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     plots           : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pose            : 12.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pretrained      : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     profile         : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     project         : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     rect            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     resume          : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     retina_masks    : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save            : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_conf       : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_crop       : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_dir        : runs/detect/train3\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_frames     : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_hybrid     : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_json       : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_period     : -1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_txt        : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     scale           : 0.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     seed            : 0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     shear           : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_boxes      : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_conf       : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_labels     : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     simplify        : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     single_cls      : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source          : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     split           : val\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     stream_buffer   : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     task            : detect\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     time            : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tracker         : botsort.yaml\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     translate       : 0.1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val             : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     verbose         : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     vid_stride      : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     visualize       : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_bias_lr  : 0.1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_epochs   : 3.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_momentum : 0.8\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     weight_decay    : 0.0005\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     workers         : 8\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     workspace       : 4\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     confusion-matrix    : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename            : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     images              : 7\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages  : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model-element       : 1 (6.24 MB)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook            : 2\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages         : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code         : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Found https://ultralytics.com/images/bus.jpg locally at bus.jpg\n",
            "image 1/1 /content/bus.jpg: 640x480 4 persons, 1 bus, 1 stop sign, 10.2ms\n",
            "Speed: 2.6ms preprocess, 10.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
              " obb: None\n",
              " orig_img: array([[[119, 146, 172],\n",
              "         [121, 148, 174],\n",
              "         [122, 152, 177],\n",
              "         ...,\n",
              "         [161, 171, 188],\n",
              "         [160, 170, 187],\n",
              "         [160, 170, 187]],\n",
              " \n",
              "        [[120, 147, 173],\n",
              "         [122, 149, 175],\n",
              "         [123, 153, 178],\n",
              "         ...,\n",
              "         [161, 171, 188],\n",
              "         [160, 170, 187],\n",
              "         [160, 170, 187]],\n",
              " \n",
              "        [[123, 150, 176],\n",
              "         [124, 151, 177],\n",
              "         [125, 155, 180],\n",
              "         ...,\n",
              "         [161, 171, 188],\n",
              "         [160, 170, 187],\n",
              "         [160, 170, 187]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[183, 182, 186],\n",
              "         [179, 178, 182],\n",
              "         [180, 179, 183],\n",
              "         ...,\n",
              "         [121, 111, 117],\n",
              "         [113, 103, 109],\n",
              "         [115, 105, 111]],\n",
              " \n",
              "        [[165, 164, 168],\n",
              "         [173, 172, 176],\n",
              "         [187, 186, 190],\n",
              "         ...,\n",
              "         [102,  92,  98],\n",
              "         [101,  91,  97],\n",
              "         [103,  93,  99]],\n",
              " \n",
              "        [[123, 122, 126],\n",
              "         [145, 144, 148],\n",
              "         [176, 175, 179],\n",
              "         ...,\n",
              "         [ 95,  85,  91],\n",
              "         [ 96,  86,  92],\n",
              "         [ 98,  88,  94]]], dtype=uint8)\n",
              " orig_shape: (1080, 810)\n",
              " path: '/content/bus.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/train32'\n",
              " speed: {'preprocess': 2.628326416015625, 'inference': 10.18834114074707, 'postprocess': 1.6815662384033203}]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Segmentation\n",
        "\n",
        "YOLOv8 _segmentation_ models use the `-seg` suffix, i.e. `yolov8n-seg.pt` and are pretrained on COCO. See [Segmentation Docs](https://docs.ultralytics.com/tasks/segment/) for full details.\n"
      ],
      "metadata": {
        "id": "7ZW58jUzK66B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load YOLOv8n-seg, train it on COCO128-seg for 3 epochs and predict an image with it\n",
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO('yolov8n-seg.pt')  # load a pretrained YOLOv8n segmentation model\n",
        "model.train(data='coco8-seg.yaml', epochs=3)  # train the model\n",
        "model('https://ultralytics.com/images/bus.jpg')  # predict on an image"
      ],
      "metadata": {
        "id": "WFPJIQl_L5HT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "111248e2-95fa-4852-a7bb-5c045f54c702"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n-seg.pt to 'yolov8n-seg.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6.74M/6.74M [00:00<00:00, 128MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.2.66 üöÄ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=yolov8n-seg.pt, data=coco8-seg.yaml, epochs=3, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
            "\n",
            "Dataset 'coco8-seg.yaml' images not found ‚ö†Ô∏è, missing path '/content/datasets/coco8-seg/images/val'\n",
            "Downloading https://ultralytics.com/assets/coco8-seg.zip to '/content/datasets/coco8-seg.zip'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 439k/439k [00:00<00:00, 15.0MB/s]\n",
            "Unzipping /content/datasets/coco8-seg.zip to /content/datasets/coco8-seg...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:00<00:00, 837.78file/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset download success ‚úÖ (0.8s), saved to \u001b[1m/content/datasets\u001b[0m\n",
            "\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1   1150432  ultralytics.nn.modules.head.Segment          [80, 32, 64, [64, 128, 256]]  \n",
            "YOLOv8n-seg summary: 261 layers, 3,409,968 parameters, 3,409,952 gradients, 12.8 GFLOPs\n",
            "\n",
            "Transferred 417/417 items from pretrained weights\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n",
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/miyachun/general/52daadca4bc54caeba23b23fa2a777ee\n",
            "\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Couldn't find a Git repository in '/content' nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/coco8-seg/labels/train... 4 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 413.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/datasets/coco8-seg/labels/train.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/coco8-seg/labels/val... 4 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 478.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/coco8-seg/labels/val.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/segment/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ‚úÖ\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
            "Starting training for 3 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        1/3      1.04G     0.8972      2.588      2.808      1.273         27        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          4         17      0.682      0.633      0.752      0.496      0.672      0.617      0.635      0.446\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        2/3     0.977G      1.283      3.467      2.873      1.459         38        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  5.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          4         17      0.694      0.633      0.748      0.487      0.672        0.6      0.622      0.442\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        3/3     0.927G     0.8506      2.795      2.998      1.176         18        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          4         17      0.711      0.633      0.751        0.5      0.686        0.6      0.624      0.442\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "3 epochs completed in 0.008 hours.\n",
            "Optimizer stripped from runs/segment/train/weights/last.pt, 7.1MB\n",
            "Optimizer stripped from runs/segment/train/weights/best.pt, 7.1MB\n",
            "\n",
            "Validating runs/segment/train/weights/best.pt...\n",
            "Ultralytics YOLOv8.2.66 üöÄ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLOv8n-seg summary (fused): 195 layers, 3,404,320 parameters, 0 gradients, 12.6 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 10.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          4         17       0.68      0.633      0.752      0.496       0.67      0.617      0.635      0.446\n",
            "                person          3         10      0.489        0.8      0.697       0.31      0.428        0.7      0.598      0.269\n",
            "                   dog          1          1      0.781          1      0.995      0.796      0.781          1      0.995      0.895\n",
            "                 horse          1          2      0.266          1      0.995       0.43      0.266          1       0.39      0.114\n",
            "              elephant          1          2          1          0       0.58      0.348          1          0       0.58      0.348\n",
            "              umbrella          1          1      0.542          1      0.995      0.895      0.542          1      0.995      0.895\n",
            "          potted plant          1          1          1          0      0.249      0.194          1          0      0.249      0.154\n",
            "Speed: 0.3ms preprocess, 7.1ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
            "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;38;5;196mCOMET ERROR:\u001b[0m We failed to read file runs/segment/train/F1_curve.png for uploading.\n",
            "Please double-check the file path and permissions\n",
            "\u001b[1;38;5;196mCOMET ERROR:\u001b[0m We failed to read file runs/segment/train/P_curve.png for uploading.\n",
            "Please double-check the file path and permissions\n",
            "\u001b[1;38;5;196mCOMET ERROR:\u001b[0m We failed to read file runs/segment/train/R_curve.png for uploading.\n",
            "Please double-check the file path and permissions\n",
            "\u001b[1;38;5;196mCOMET ERROR:\u001b[0m We failed to read file runs/segment/train/PR_curve.png for uploading.\n",
            "Please double-check the file path and permissions\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : indirect_gravel_2864\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/miyachun/general/52daadca4bc54caeba23b23fa2a777ee\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg0 [7]               : (0.0, 8.092e-07)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg1 [7]               : (0.0, 8.092e-07)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg2 [7]               : (0.0, 8.092e-07)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/mAP50(B) [8]     : (0.74815, 0.7517572214550157)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/mAP50(M) [8]     : (0.6221, 0.6345578930056871)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/mAP50-95(B) [8]  : (0.48693, 0.49954)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/mAP50-95(M) [8]  : (0.44186, 0.4461707231630026)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/precision(B) [8] : (0.6797094237800848, 0.71059)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/precision(M) [8] : (0.6695188798447931, 0.68628)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/recall(B) [8]    : (0.63333, 0.6333333333333333)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/recall(M) [8]    : (0.6, 0.61667)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/GFLOPs             : 12.773\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/parameters         : 3409968\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/speed_PyTorch(ms)  : 70.606\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/box_loss [6]       : (0.85065, 1.28307)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/cls_loss [6]       : (2.80831, 2.99754)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/dfl_loss [6]       : (1.17568, 1.45865)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/seg_loss [6]       : (2.58834, 3.46723)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/box_loss [6]         : (1.65203, 1.66804)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/cls_loss [6]         : (1.397, 1.4112)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/dfl_loss [6]         : (1.38134, 1.38799)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/seg_loss [6]         : (2.66416, 2.6696)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_batch_logging_interval  : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     log_confusion_matrix_on_eval : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     log_image_predictions        : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_image_predictions        : 100\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     agnostic_nms    : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     amp             : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     augment         : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     auto_augment    : randaugment\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     batch           : 16\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     bgr             : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     box             : 7.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cache           : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cfg             : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     classes         : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     close_mosaic    : 10\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cls             : 0.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conf            : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     copy_paste      : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cos_lr          : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     crop_fraction   : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     data            : /usr/local/lib/python3.10/dist-packages/ultralytics/cfg/datasets/coco8-seg.yaml\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     degrees         : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     deterministic   : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     device          : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dfl             : 1.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dnn             : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dropout         : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dynamic         : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     embed           : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     epochs          : 3\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     erasing         : 0.4\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     exist_ok        : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fliplr          : 0.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     flipud          : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     format          : torchscript\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fraction        : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     freeze          : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     half            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_h           : 0.015\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_s           : 0.7\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_v           : 0.4\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     imgsz           : 640\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     int8            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     iou             : 0.7\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     keras           : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     kobj            : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     label_smoothing : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     line_width      : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr0             : 0.01\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lrf             : 0.01\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mask_ratio      : 4\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_det         : 300\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mixup           : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mode            : train\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model           : yolov8n-seg.pt\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     momentum        : 0.937\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mosaic          : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     multi_scale     : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name            : train\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     nbs             : 64\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     nms             : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     opset           : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimize        : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimizer       : auto\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     overlap_mask    : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     patience        : 100\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     perspective     : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     plots           : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pose            : 12.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pretrained      : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     profile         : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     project         : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     rect            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     resume          : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     retina_masks    : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save            : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_conf       : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_crop       : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_dir        : runs/segment/train\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_frames     : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_hybrid     : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_json       : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_period     : -1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_txt        : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     scale           : 0.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     seed            : 0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     shear           : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_boxes      : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_conf       : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_labels     : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     simplify        : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     single_cls      : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source          : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     split           : val\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     stream_buffer   : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     task            : segment\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     time            : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tracker         : botsort.yaml\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     translate       : 0.1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val             : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     verbose         : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     vid_stride      : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     visualize       : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_bias_lr  : 0.1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_epochs   : 3.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_momentum : 0.8\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     weight_decay    : 0.0005\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     workers         : 8\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     workspace       : 4\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     confusion-matrix    : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename            : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     images              : 3\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages  : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model-element       : 1 (6.74 MB)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook            : 2\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages         : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code         : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Found https://ultralytics.com/images/bus.jpg locally at bus.jpg\n",
            "image 1/1 /content/bus.jpg: 640x480 4 persons, 1 bus, 1 skateboard, 57.2ms\n",
            "Speed: 3.4ms preprocess, 57.2ms inference, 6.3ms postprocess per image at shape (1, 3, 640, 480)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: ultralytics.engine.results.Masks object\n",
              " names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
              " obb: None\n",
              " orig_img: array([[[119, 146, 172],\n",
              "         [121, 148, 174],\n",
              "         [122, 152, 177],\n",
              "         ...,\n",
              "         [161, 171, 188],\n",
              "         [160, 170, 187],\n",
              "         [160, 170, 187]],\n",
              " \n",
              "        [[120, 147, 173],\n",
              "         [122, 149, 175],\n",
              "         [123, 153, 178],\n",
              "         ...,\n",
              "         [161, 171, 188],\n",
              "         [160, 170, 187],\n",
              "         [160, 170, 187]],\n",
              " \n",
              "        [[123, 150, 176],\n",
              "         [124, 151, 177],\n",
              "         [125, 155, 180],\n",
              "         ...,\n",
              "         [161, 171, 188],\n",
              "         [160, 170, 187],\n",
              "         [160, 170, 187]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[183, 182, 186],\n",
              "         [179, 178, 182],\n",
              "         [180, 179, 183],\n",
              "         ...,\n",
              "         [121, 111, 117],\n",
              "         [113, 103, 109],\n",
              "         [115, 105, 111]],\n",
              " \n",
              "        [[165, 164, 168],\n",
              "         [173, 172, 176],\n",
              "         [187, 186, 190],\n",
              "         ...,\n",
              "         [102,  92,  98],\n",
              "         [101,  91,  97],\n",
              "         [103,  93,  99]],\n",
              " \n",
              "        [[123, 122, 126],\n",
              "         [145, 144, 148],\n",
              "         [176, 175, 179],\n",
              "         ...,\n",
              "         [ 95,  85,  91],\n",
              "         [ 96,  86,  92],\n",
              "         [ 98,  88,  94]]], dtype=uint8)\n",
              " orig_shape: (1080, 810)\n",
              " path: '/content/bus.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/segment/train2'\n",
              " speed: {'preprocess': 3.4325122833251953, 'inference': 57.172298431396484, 'postprocess': 6.303071975708008}]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Classification\n",
        "\n",
        "YOLOv8 _classification_ models use the `-cls` suffix, i.e. `yolov8n-cls.pt` and are pretrained on ImageNet. See [Classification Docs](https://docs.ultralytics.com/tasks/classify/) for full details.\n"
      ],
      "metadata": {
        "id": "ax3p94VNK9zR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load YOLOv8n-cls, train it on mnist160 for 3 epochs and predict an image with it\n",
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO('yolov8n-cls.pt')  # load a pretrained YOLOv8n classification model\n",
        "model.train(data='mnist160', epochs=3)  # train the model\n",
        "model('https://ultralytics.com/images/bus.jpg')  # predict on an image"
      ],
      "metadata": {
        "id": "5q9Zu6zlL5rS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e48f0ea9-84ea-4c45-b5de-8c404dcde688"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n-cls.pt to 'yolov8n-cls.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5.31M/5.31M [00:00<00:00, 99.2MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.2.66 üöÄ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=mnist160, epochs=3, time=None, patience=100, batch=16, imgsz=224, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/train\n",
            "\n",
            "Dataset not found ‚ö†Ô∏è, missing path /content/datasets/mnist160, attempting download...\n",
            "Downloading https://ultralytics.com/assets/mnist160.zip to '/content/datasets/mnist160.zip'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70.0k/70.0k [00:00<00:00, 6.18MB/s]\n",
            "Unzipping /content/datasets/mnist160.zip to /content/datasets/mnist160...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 184/184 [00:00<00:00, 8632.19file/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset download success ‚úÖ (0.7s), saved to \u001b[1m/content/datasets/mnist160\u001b[0m\n",
            "\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/datasets/mnist160/train... found 80 images in 10 classes ‚úÖ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m None...\n",
            "\u001b[34m\u001b[1mtest:\u001b[0m /content/datasets/mnist160/test... found 80 images in 10 classes ‚úÖ \n",
            "Overriding model.yaml nc=1000 with nc=10\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    343050  ultralytics.nn.modules.head.Classify         [256, 10]                     \n",
            "YOLOv8n-cls summary: 99 layers, 1,451,098 parameters, 1,451,098 gradients, 3.4 GFLOPs\n",
            "Transferred 156/158 items from pretrained weights\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n",
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/miyachun/general/0e7a1e0726c24a9c9252abdd46460c6a\n",
            "\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Couldn't find a Git repository in '/content' nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/classify/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/mnist160/train... 80 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80/80 [00:00<00:00, 5799.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/datasets/mnist160/train.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/mnist160/test... 80 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80/80 [00:00<00:00, 9093.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/mnist160/test.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ‚úÖ\n",
            "Image sizes 224 train, 224 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/classify/train\u001b[0m\n",
            "Starting training for 3 epochs...\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        1/3     0.602G      2.334         16        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  4.34it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 15.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        0.1      0.525\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        2/3     0.436G      2.328         16        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 11.36it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 21.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.075        0.6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        3/3     0.432G      2.315         16        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00,  8.52it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 24.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all     0.0875      0.625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "3 epochs completed in 0.007 hours.\n",
            "Optimizer stripped from runs/classify/train/weights/last.pt, 3.0MB\n",
            "Optimizer stripped from runs/classify/train/weights/best.pt, 3.0MB\n",
            "\n",
            "Validating runs/classify/train/weights/best.pt...\n",
            "Ultralytics YOLOv8.2.66 üöÄ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLOv8n-cls summary (fused): 73 layers, 1,447,690 parameters, 0 gradients, 3.3 GFLOPs\n",
            "WARNING ‚ö†Ô∏è Dataset 'split=val' not found, using 'split=test' instead.\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/datasets/mnist160/train... found 80 images in 10 classes ‚úÖ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m None...\n",
            "\u001b[34m\u001b[1mtest:\u001b[0m /content/datasets/mnist160/test... found 80 images in 10 classes ‚úÖ \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 17.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all     0.0875      0.625\n",
            "Speed: 0.3ms preprocess, 0.6ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1mruns/classify/train\u001b[0m\n",
            "Results saved to \u001b[1mruns/classify/train\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;38;5;196mCOMET ERROR:\u001b[0m We failed to read file runs/classify/train/F1_curve.png for uploading.\n",
            "Please double-check the file path and permissions\n",
            "\u001b[1;38;5;196mCOMET ERROR:\u001b[0m We failed to read file runs/classify/train/P_curve.png for uploading.\n",
            "Please double-check the file path and permissions\n",
            "\u001b[1;38;5;196mCOMET ERROR:\u001b[0m We failed to read file runs/classify/train/R_curve.png for uploading.\n",
            "Please double-check the file path and permissions\n",
            "\u001b[1;38;5;196mCOMET ERROR:\u001b[0m We failed to read file runs/classify/train/PR_curve.png for uploading.\n",
            "Please double-check the file path and permissions\n",
            "\u001b[1;38;5;196mCOMET ERROR:\u001b[0m We failed to read file runs/classify/train/labels.jpg for uploading.\n",
            "Please double-check the file path and permissions\n",
            "\u001b[1;38;5;196mCOMET ERROR:\u001b[0m We failed to read file runs/classify/train/labels_correlogram.jpg for uploading.\n",
            "Please double-check the file path and permissions\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : ideal_pagoda_4681\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/miyachun/general/0e7a1e0726c24a9c9252abdd46460c6a\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg0 [7]                : (2.856e-05, 4.3054200000000005e-05)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg1 [7]                : (2.856e-05, 4.3054200000000005e-05)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg2 [7]                : (2.856e-05, 4.3054200000000005e-05)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/accuracy_top1 [8] : (0.075, 0.1)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/accuracy_top5 [8] : (0.525, 0.625)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/GFLOPs              : 3.37\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/parameters          : 1451098\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/speed_PyTorch(ms)   : 2.207\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/loss [6]            : (2.31493, 2.33372)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/loss [6]              : (2.29883, 2.30273)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_batch_logging_interval  : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     log_confusion_matrix_on_eval : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     log_image_predictions        : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_image_predictions        : 100\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     agnostic_nms    : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     amp             : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     augment         : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     auto_augment    : randaugment\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     batch           : 16\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     bgr             : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     box             : 7.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cache           : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cfg             : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     classes         : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     close_mosaic    : 10\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cls             : 0.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conf            : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     copy_paste      : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cos_lr          : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     crop_fraction   : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     data            : mnist160\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     degrees         : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     deterministic   : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     device          : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dfl             : 1.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dnn             : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dropout         : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dynamic         : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     embed           : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     epochs          : 3\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     erasing         : 0.4\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     exist_ok        : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fliplr          : 0.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     flipud          : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     format          : torchscript\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fraction        : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     freeze          : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     half            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_h           : 0.015\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_s           : 0.7\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_v           : 0.4\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     imgsz           : 224\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     int8            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     iou             : 0.7\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     keras           : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     kobj            : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     label_smoothing : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     line_width      : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr0             : 0.01\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lrf             : 0.01\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mask_ratio      : 4\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_det         : 300\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mixup           : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mode            : train\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model           : yolov8n-cls.pt\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     momentum        : 0.937\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mosaic          : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     multi_scale     : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name            : train\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     nbs             : 64\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     nms             : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     opset           : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimize        : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimizer       : auto\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     overlap_mask    : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     patience        : 100\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     perspective     : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     plots           : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pose            : 12.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pretrained      : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     profile         : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     project         : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     rect            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     resume          : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     retina_masks    : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save            : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_conf       : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_crop       : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_dir        : runs/classify/train\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_frames     : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_hybrid     : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_json       : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_period     : -1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_txt        : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     scale           : 0.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     seed            : 0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     shear           : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_boxes      : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_conf       : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_labels     : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     simplify        : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     single_cls      : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source          : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     split           : val\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     stream_buffer   : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     task            : classify\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     time            : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tracker         : botsort.yaml\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     translate       : 0.1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val             : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     verbose         : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     vid_stride      : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     visualize       : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_bias_lr  : 0.1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_epochs   : 3.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_momentum : 0.8\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     weight_decay    : 0.0005\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     workers         : 8\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     workspace       : 4\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     confusion-matrix    : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename            : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     images              : 4\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages  : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model-element       : 1 (2.85 MB)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook            : 2\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages         : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code         : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Uploading 1 metrics, params and output messages\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Found https://ultralytics.com/images/bus.jpg locally at bus.jpg\n",
            "image 1/1 /content/bus.jpg: 224x224 9 0.20, 6 0.12, 8 0.12, 0 0.11, 2 0.11, 5.4ms\n",
            "Speed: 15.9ms preprocess, 5.4ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: None\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6', 7: '7', 8: '8', 9: '9'}\n",
              " obb: None\n",
              " orig_img: array([[[119, 146, 172],\n",
              "         [121, 148, 174],\n",
              "         [122, 152, 177],\n",
              "         ...,\n",
              "         [161, 171, 188],\n",
              "         [160, 170, 187],\n",
              "         [160, 170, 187]],\n",
              " \n",
              "        [[120, 147, 173],\n",
              "         [122, 149, 175],\n",
              "         [123, 153, 178],\n",
              "         ...,\n",
              "         [161, 171, 188],\n",
              "         [160, 170, 187],\n",
              "         [160, 170, 187]],\n",
              " \n",
              "        [[123, 150, 176],\n",
              "         [124, 151, 177],\n",
              "         [125, 155, 180],\n",
              "         ...,\n",
              "         [161, 171, 188],\n",
              "         [160, 170, 187],\n",
              "         [160, 170, 187]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[183, 182, 186],\n",
              "         [179, 178, 182],\n",
              "         [180, 179, 183],\n",
              "         ...,\n",
              "         [121, 111, 117],\n",
              "         [113, 103, 109],\n",
              "         [115, 105, 111]],\n",
              " \n",
              "        [[165, 164, 168],\n",
              "         [173, 172, 176],\n",
              "         [187, 186, 190],\n",
              "         ...,\n",
              "         [102,  92,  98],\n",
              "         [101,  91,  97],\n",
              "         [103,  93,  99]],\n",
              " \n",
              "        [[123, 122, 126],\n",
              "         [145, 144, 148],\n",
              "         [176, 175, 179],\n",
              "         ...,\n",
              "         [ 95,  85,  91],\n",
              "         [ 96,  86,  92],\n",
              "         [ 98,  88,  94]]], dtype=uint8)\n",
              " orig_shape: (1080, 810)\n",
              " path: '/content/bus.jpg'\n",
              " probs: ultralytics.engine.results.Probs object\n",
              " save_dir: 'runs/classify/train2'\n",
              " speed: {'preprocess': 15.862226486206055, 'inference': 5.410432815551758, 'postprocess': 0.10561943054199219}]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Pose\n",
        "\n",
        "YOLOv8 _pose_ models use the `-pose` suffix, i.e. `yolov8n-pose.pt` and are pretrained on COCO Keypoints. See [Pose Docs](https://docs.ultralytics.com/tasks/pose/) for full details."
      ],
      "metadata": {
        "id": "SpIaFLiO11TG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load YOLOv8n-pose, train it on COCO8-pose for 3 epochs and predict an image with it\n",
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO('yolov8n-pose.pt')  # load a pretrained YOLOv8n pose model\n",
        "model.train(data='coco8-pose.yaml', epochs=3)  # train the model\n",
        "model('https://ultralytics.com/images/bus.jpg')  # predict on an image"
      ],
      "metadata": {
        "id": "si4aKFNg19vX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43c17512-f3f5-45b9-92c6-a3041895dbd4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n-pose.pt to 'yolov8n-pose.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6.52M/6.52M [00:00<00:00, 126MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.2.66 üöÄ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=pose, mode=train, model=yolov8n-pose.pt, data=coco8-pose.yaml, epochs=3, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/pose/train\n",
            "\n",
            "Dataset 'coco8-pose.yaml' images not found ‚ö†Ô∏è, missing path '/content/datasets/coco8-pose/images/val'\n",
            "Downloading https://ultralytics.com/assets/coco8-pose.zip to '/content/datasets/coco8-pose.zip'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 334k/334k [00:00<00:00, 17.2MB/s]\n",
            "Unzipping /content/datasets/coco8-pose.zip to /content/datasets/coco8-pose...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27/27 [00:00<00:00, 3749.75file/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset download success ‚úÖ (0.7s), saved to \u001b[1m/content/datasets\u001b[0m\n",
            "\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1   1035934  ultralytics.nn.modules.head.Pose             [1, [17, 3], [64, 128, 256]]  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YOLOv8n-pose summary: 250 layers, 3,295,470 parameters, 3,295,454 gradients, 9.3 GFLOPs\n",
            "\n",
            "Transferred 397/397 items from pretrained weights\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n",
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/miyachun/general/7a8b4961500b43428eac95f0c4328506\n",
            "\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Couldn't find a Git repository in '/content' nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/pose/train', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/coco8-pose/labels/train... 4 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 1190.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/datasets/coco8-pose/labels/train.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/coco8-pose/labels/val... 4 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 523.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/coco8-pose/labels/val.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/pose/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 63 weight(decay=0.0), 73 weight(decay=0.0005), 72 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ‚úÖ\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/pose/train\u001b[0m\n",
            "Starting training for 3 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        1/3     0.799G      1.196      2.997     0.2851     0.8514      1.463         12        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.38it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          4         14      0.927      0.905      0.907      0.668      0.846        0.5      0.535      0.352\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        2/3     0.755G      1.104      3.305     0.3061     0.8659      1.285         15        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          4         14      0.929      0.929      0.907      0.668      0.845        0.5      0.535      0.352\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        3/3     0.749G      1.214      4.142     0.3471      1.108      1.197         20        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  6.68it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          4         14      0.903      0.929      0.907      0.668      0.843        0.5      0.535      0.351\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "3 epochs completed in 0.009 hours.\n",
            "Optimizer stripped from runs/pose/train/weights/last.pt, 6.8MB\n",
            "Optimizer stripped from runs/pose/train/weights/best.pt, 6.8MB\n",
            "\n",
            "Validating runs/pose/train/weights/best.pt...\n",
            "Ultralytics YOLOv8.2.66 üöÄ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLOv8n-pose summary (fused): 187 layers, 3,289,964 parameters, 0 gradients, 9.2 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 18.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          4         14      0.927      0.906      0.907      0.668      0.846        0.5      0.535      0.352\n",
            "Speed: 0.3ms preprocess, 4.0ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
            "Results saved to \u001b[1mruns/pose/train\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;38;5;196mCOMET ERROR:\u001b[0m We failed to read file runs/pose/train/F1_curve.png for uploading.\n",
            "Please double-check the file path and permissions\n",
            "\u001b[1;38;5;196mCOMET ERROR:\u001b[0m We failed to read file runs/pose/train/P_curve.png for uploading.\n",
            "Please double-check the file path and permissions\n",
            "\u001b[1;38;5;196mCOMET ERROR:\u001b[0m We failed to read file runs/pose/train/R_curve.png for uploading.\n",
            "Please double-check the file path and permissions\n",
            "\u001b[1;38;5;196mCOMET ERROR:\u001b[0m We failed to read file runs/pose/train/PR_curve.png for uploading.\n",
            "Please double-check the file path and permissions\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : electric_rubble_9110\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/miyachun/general/7a8b4961500b43428eac95f0c4328506\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg0 [7]               : (0.0, 1.36e-05)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg1 [7]               : (0.0, 1.36e-05)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg2 [7]               : (0.0, 1.36e-05)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/mAP50(B) [8]     : (0.90731, 0.90734)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/mAP50(P) [8]     : (0.53456, 0.53466)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/mAP50-95(B) [8]  : (0.66815, 0.66837)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/mAP50-95(P) [8]  : (0.3507, 0.35192197911322565)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/precision(B) [8] : (0.903, 0.92855)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/precision(P) [8] : (0.84346, 0.84619)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/recall(B) [8]    : (0.90519, 0.92857)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/recall(P)        : 0.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/GFLOPs             : 9.296\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/parameters         : 3295470\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/speed_PyTorch(ms)  : 61.442\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/box_loss [6]       : (1.10439, 1.21351)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/cls_loss [6]       : (0.85138, 1.10847)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/dfl_loss [6]       : (1.19733, 1.46328)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/kobj_loss [6]      : (0.2851, 0.34711)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/pose_loss [6]      : (2.99691, 4.14188)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/box_loss [6]         : (0.89525, 0.89865)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/cls_loss [6]         : (0.58062, 0.58556)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/dfl_loss [6]         : (1.05483, 1.05779)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/kobj_loss [6]        : (0.34577, 0.35698)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/pose_loss [6]        : (3.53093, 3.57048)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_batch_logging_interval  : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     log_confusion_matrix_on_eval : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     log_image_predictions        : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_image_predictions        : 100\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     agnostic_nms    : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     amp             : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     augment         : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     auto_augment    : randaugment\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     batch           : 16\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     bgr             : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     box             : 7.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cache           : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cfg             : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     classes         : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     close_mosaic    : 10\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cls             : 0.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conf            : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     copy_paste      : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cos_lr          : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     crop_fraction   : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     data            : /usr/local/lib/python3.10/dist-packages/ultralytics/cfg/datasets/coco8-pose.yaml\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     degrees         : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     deterministic   : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     device          : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dfl             : 1.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dnn             : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dropout         : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dynamic         : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     embed           : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     epochs          : 3\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     erasing         : 0.4\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     exist_ok        : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fliplr          : 0.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     flipud          : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     format          : torchscript\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fraction        : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     freeze          : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     half            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_h           : 0.015\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_s           : 0.7\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_v           : 0.4\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     imgsz           : 640\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     int8            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     iou             : 0.7\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     keras           : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     kobj            : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     label_smoothing : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     line_width      : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr0             : 0.01\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lrf             : 0.01\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mask_ratio      : 4\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_det         : 300\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mixup           : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mode            : train\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model           : yolov8n-pose.pt\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     momentum        : 0.937\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mosaic          : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     multi_scale     : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name            : train\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     nbs             : 64\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     nms             : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     opset           : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimize        : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimizer       : auto\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     overlap_mask    : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     patience        : 100\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     perspective     : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     plots           : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pose            : 12.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pretrained      : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     profile         : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     project         : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     rect            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     resume          : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     retina_masks    : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save            : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_conf       : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_crop       : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_dir        : runs/pose/train\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_frames     : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_hybrid     : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_json       : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_period     : -1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_txt        : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     scale           : 0.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     seed            : 0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     shear           : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_boxes      : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_conf       : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_labels     : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     simplify        : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     single_cls      : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source          : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     split           : val\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     stream_buffer   : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     task            : pose\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     time            : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tracker         : botsort.yaml\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     translate       : 0.1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val             : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     verbose         : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     vid_stride      : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     visualize       : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_bias_lr  : 0.1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_epochs   : 3.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_momentum : 0.8\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     weight_decay    : 0.0005\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     workers         : 8\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     workspace       : 4\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     confusion-matrix    : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename            : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     images              : 3\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages  : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model-element       : 1 (6.51 MB)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook            : 2\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages         : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code         : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Uploading 158 metrics, params and output messages\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Found https://ultralytics.com/images/bus.jpg locally at bus.jpg\n",
            "image 1/1 /content/bus.jpg: 640x480 4 persons, 44.2ms\n",
            "Speed: 2.3ms preprocess, 44.2ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 480)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: ultralytics.engine.results.Keypoints object\n",
              " masks: None\n",
              " names: {0: 'person'}\n",
              " obb: None\n",
              " orig_img: array([[[119, 146, 172],\n",
              "         [121, 148, 174],\n",
              "         [122, 152, 177],\n",
              "         ...,\n",
              "         [161, 171, 188],\n",
              "         [160, 170, 187],\n",
              "         [160, 170, 187]],\n",
              " \n",
              "        [[120, 147, 173],\n",
              "         [122, 149, 175],\n",
              "         [123, 153, 178],\n",
              "         ...,\n",
              "         [161, 171, 188],\n",
              "         [160, 170, 187],\n",
              "         [160, 170, 187]],\n",
              " \n",
              "        [[123, 150, 176],\n",
              "         [124, 151, 177],\n",
              "         [125, 155, 180],\n",
              "         ...,\n",
              "         [161, 171, 188],\n",
              "         [160, 170, 187],\n",
              "         [160, 170, 187]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[183, 182, 186],\n",
              "         [179, 178, 182],\n",
              "         [180, 179, 183],\n",
              "         ...,\n",
              "         [121, 111, 117],\n",
              "         [113, 103, 109],\n",
              "         [115, 105, 111]],\n",
              " \n",
              "        [[165, 164, 168],\n",
              "         [173, 172, 176],\n",
              "         [187, 186, 190],\n",
              "         ...,\n",
              "         [102,  92,  98],\n",
              "         [101,  91,  97],\n",
              "         [103,  93,  99]],\n",
              " \n",
              "        [[123, 122, 126],\n",
              "         [145, 144, 148],\n",
              "         [176, 175, 179],\n",
              "         ...,\n",
              "         [ 95,  85,  91],\n",
              "         [ 96,  86,  92],\n",
              "         [ 98,  88,  94]]], dtype=uint8)\n",
              " orig_shape: (1080, 810)\n",
              " path: '/content/bus.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/pose/train2'\n",
              " speed: {'preprocess': 2.2547245025634766, 'inference': 44.20638084411621, 'postprocess': 2.769947052001953}]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Oriented Bounding Boxes (OBB)\n",
        "\n",
        "YOLOv8 _OBB_ models use the `-obb` suffix, i.e. `yolov8n-obb.pt` and are pretrained on the DOTA dataset. See [OBB Docs](https://docs.ultralytics.com/tasks/obb/) for full details."
      ],
      "metadata": {
        "id": "cf5j_T9-B5F0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load YOLOv8n-obb, train it on DOTA8 for 3 epochs and predict an image with it\n",
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO('yolov8n-obb.pt')  # load a pretrained YOLOv8n OBB model\n",
        "model.train(data='coco8-dota.yaml', epochs=3)  # train the model\n",
        "model('https://ultralytics.com/images/bus.jpg')  # predict on an image"
      ],
      "metadata": {
        "id": "IJNKClOOB5YS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8c2d1fe4-e21e-4186-990d-50ad0bd04c51"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.2.66 üöÄ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=obb, mode=train, model=yolov8n-obb.pt, data=coco8.yaml, epochs=3, time=None, patience=100, batch=16, imgsz=1024, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/obb/train2\n",
            "Overriding model.yaml nc=15 with nc=80\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    969331  ultralytics.nn.modules.head.OBB              [80, 1, [64, 128, 256]]       \n",
            "YOLOv8n-obb summary: 250 layers, 3,228,867 parameters, 3,228,851 gradients, 9.1 GFLOPs\n",
            "\n",
            "Transferred 361/397 items from pretrained weights\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n",
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/miyachun/general/0069e94c1cae4340b5e660f5b0a4a113\n",
            "\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Couldn't find a Git repository in '/content' nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/obb/train2', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/coco8/labels/train.cache... 4 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/coco8/labels/val.cache... 4 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/obb/train2/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 63 weight(decay=0.0), 73 weight(decay=0.0005), 72 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ‚úÖ\n",
            "Image sizes 1024 train, 1024 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/obb/train2\u001b[0m\n",
            "Starting training for 3 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ERROR ‚ùå OBB dataset incorrectly formatted or not a OBB dataset.\nThis error can occur when incorrectly training a 'OBB' model on a 'detect' dataset, i.e. 'yolo train model=yolov8n-obb.pt data=dota8.yaml'.\nVerify your dataset is a correctly formatted 'OBB' dataset using 'data=dota8.yaml' as an example.\nSee https://docs.ultralytics.com/datasets/obb/ for help.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/utils/loss.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, preds, batch)\u001b[0m\n\u001b[1;32m    657\u001b[0m             \u001b[0mbatch_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"batch_idx\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m             \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"cls\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"bboxes\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m             \u001b[0mrw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mimgsz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mimgsz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Expected size 25 but got size 0 for tensor number 2 in the list.",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-577b4bdba602>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYOLO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'yolov8n-obb.pt'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# load a pretrained YOLOv8n OBB model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'coco8.yaml'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://ultralytics.com/images/bus.jpg'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# predict on an image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    809\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhub_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m  \u001b[0;31m# attach optional HUB session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m         \u001b[0;31m# Update model and cfg after training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mRANK\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setup_scheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36m_do_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    380\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m                     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mRANK\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mworld_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/nn/tasks.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \"\"\"\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# for cases of training and validating while training.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/nn/tasks.py\u001b[0m in \u001b[0;36mloss\u001b[0;34m(self, batch, preds)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"img\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minit_criterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/utils/loss.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, preds, batch)\u001b[0m\n\u001b[1;32m    663\u001b[0m             \u001b[0mmask_gt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgt_bboxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgt_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 665\u001b[0;31m             raise TypeError(\n\u001b[0m\u001b[1;32m    666\u001b[0m                 \u001b[0;34m\"ERROR ‚ùå OBB dataset incorrectly formatted or not a OBB dataset.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m                 \u001b[0;34m\"This error can occur when incorrectly training a 'OBB' model on a 'detect' dataset, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: ERROR ‚ùå OBB dataset incorrectly formatted or not a OBB dataset.\nThis error can occur when incorrectly training a 'OBB' model on a 'detect' dataset, i.e. 'yolo train model=yolov8n-obb.pt data=dota8.yaml'.\nVerify your dataset is a correctly formatted 'OBB' dataset using 'data=dota8.yaml' as an example.\nSee https://docs.ultralytics.com/datasets/obb/ for help."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEijrePND_2I"
      },
      "source": [
        "# Appendix\n",
        "\n",
        "Additional content below."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pip install from source\n",
        "!pip install git+https://github.com/ultralytics/ultralytics@main"
      ],
      "metadata": {
        "id": "pIdE6i8C3LYp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b49bb32e-e8f1-417d-acbd-13daf9f0fe60"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/ultralytics/ultralytics@main\n",
            "  Cloning https://github.com/ultralytics/ultralytics (to revision main) to /tmp/pip-req-build-z2yd35_u\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/ultralytics/ultralytics /tmp/pip-req-build-z2yd35_u\n",
            "  Resolved https://github.com/ultralytics/ultralytics to commit 673e76b86282859ead5517bd04dee896a647db93\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.2.66) (1.25.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.2.66) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.2.66) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.2.66) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.2.66) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.2.66) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.2.66) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.2.66) (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.2.66) (0.18.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.2.66) (4.66.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.2.66) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.2.66) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.2.66) (2.0.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.2.66) (0.13.1)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.2.66) (2.0.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics==8.2.66) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics==8.2.66) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics==8.2.66) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics==8.2.66) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics==8.2.66) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics==8.2.66) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics==8.2.66) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics==8.2.66) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics==8.2.66) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics==8.2.66) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics==8.2.66) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics==8.2.66) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics==8.2.66) (2024.7.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics==8.2.66) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics==8.2.66) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics==8.2.66) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics==8.2.66) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics==8.2.66) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics==8.2.66) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics==8.2.66) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics==8.2.66) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics==8.2.66) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics==8.2.66) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics==8.2.66) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics==8.2.66) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics==8.2.66) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics==8.2.66) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics==8.2.66) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics==8.2.66) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics==8.2.66) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics==8.2.66) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics==8.2.66) (12.5.82)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics==8.2.66) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics==8.2.66) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics==8.2.66) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Git clone and run tests on updates branch\n",
        "!git clone https://github.com/ultralytics/ultralytics -b main\n",
        "%pip install -qe ultralytics"
      ],
      "metadata": {
        "id": "uRKlwxSJdhd1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf6e07fc-66e3-498a-db23-ca820bbb3003"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ultralytics'...\n",
            "remote: Enumerating objects: 31547, done.\u001b[K\n",
            "remote: Counting objects: 100% (211/211), done.\u001b[K\n",
            "remote: Compressing objects: 100% (121/121), done.\u001b[K\n",
            "remote: Total 31547 (delta 145), reused 144 (delta 90), pack-reused 31336\u001b[K\n",
            "Receiving objects: 100% (31547/31547), 15.58 MiB | 18.79 MiB/s, done.\n",
            "Resolving deltas: 100% (22872/22872), done.\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building editable for ultralytics (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run tests (Git clone only)\n",
        "!pytest ultralytics/tests"
      ],
      "metadata": {
        "id": "GtPlh7mcCGZX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79e97cc7-00f5-40f1-b4b3-7cb90a2b1c4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m======================================= test session starts ========================================\u001b[0m\n",
            "platform linux -- Python 3.10.12, pytest-7.4.4, pluggy-1.5.0\n",
            "rootdir: /content/ultralytics\n",
            "configfile: pyproject.toml\n",
            "plugins: typeguard-4.3.0, anyio-3.7.1\n",
            "collected 259 items                                                                                \u001b[0m\n",
            "\n",
            "ultralytics/tests/test_cli.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Validate multiple models\n",
        "for x in 'nsmlx':\n",
        "  !yolo val model=yolov8{x}.pt data=coco.yaml"
      ],
      "metadata": {
        "id": "Wdc6t_bfzDDk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}